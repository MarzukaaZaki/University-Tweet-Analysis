{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9557236,"sourceType":"datasetVersion","datasetId":5823699},{"sourceId":10047505,"sourceType":"datasetVersion","datasetId":6190142},{"sourceId":10047507,"sourceType":"datasetVersion","datasetId":6190144},{"sourceId":10047510,"sourceType":"datasetVersion","datasetId":6190147},{"sourceId":10047577,"sourceType":"datasetVersion","datasetId":6190190},{"sourceId":10613825,"sourceType":"datasetVersion","datasetId":6570983},{"sourceId":10993040,"sourceType":"datasetVersion","datasetId":6842571}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport random\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\nfrom tabulate import tabulate\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom termcolor import colored\nimport os\nfrom typing import List, Dict, Union\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2025-04-24T05:46:05.806154Z","iopub.execute_input":"2025-04-24T05:46:05.806450Z","iopub.status.idle":"2025-04-24T05:46:24.871863Z","shell.execute_reply.started":"2025-04-24T05:46:05.806417Z","shell.execute_reply":"2025-04-24T05:46:24.871099Z"},"trusted":true,"id":"CqFLXH0qogPy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"directory_path = '/kaggle/input/iteration5-992tweets/Iterations - Iteration5.csv'","metadata":{"id":"Pd7peNKUuAnQ","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T05:46:24.873951Z","iopub.execute_input":"2025-04-24T05:46:24.874512Z","iopub.status.idle":"2025-04-24T05:46:24.878449Z","shell.execute_reply.started":"2025-04-24T05:46:24.874484Z","shell.execute_reply":"2025-04-24T05:46:24.877607Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the Dataset","metadata":{"id":"UqrzSoSTogP1"}},{"cell_type":"code","source":"# Load the dataset\ndf = pd.read_csv(directory_path)","metadata":{"execution":{"iopub.status.busy":"2025-04-24T05:46:24.884946Z","iopub.execute_input":"2025-04-24T05:46:24.885307Z","iopub.status.idle":"2025-04-24T05:46:24.938697Z","shell.execute_reply.started":"2025-04-24T05:46:24.885263Z","shell.execute_reply":"2025-04-24T05:46:24.937871Z"},"trusted":true,"id":"KsNLtpAHogP3"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"id":"pegMW2XyogP3","outputId":"a59ae42e-28f6-46ce-d74e-43281622f2eb","execution":{"iopub.status.busy":"2025-04-24T05:46:24.939649Z","iopub.execute_input":"2025-04-24T05:46:24.939904Z","iopub.status.idle":"2025-04-24T05:46:24.945998Z","shell.execute_reply.started":"2025-04-24T05:46:24.939879Z","shell.execute_reply":"2025-04-24T05:46:24.945219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"University\"].nunique()","metadata":{"trusted":true,"id":"Yh8IhwgDogP4","outputId":"761e4247-225a-418c-dc1d-89360812d198","execution":{"iopub.status.busy":"2025-04-24T05:46:24.948545Z","iopub.execute_input":"2025-04-24T05:46:24.948859Z","iopub.status.idle":"2025-04-24T05:46:24.961564Z","shell.execute_reply.started":"2025-04-24T05:46:24.948815Z","shell.execute_reply":"2025-04-24T05:46:24.960639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"DEI\"].value_counts()","metadata":{"trusted":true,"id":"6PIVtYVIogP5","outputId":"048f93f1-d8f3-4902-9f01-832ca38a123f","execution":{"iopub.status.busy":"2025-04-24T05:46:24.962492Z","iopub.execute_input":"2025-04-24T05:46:24.962864Z","iopub.status.idle":"2025-04-24T05:46:24.977187Z","shell.execute_reply.started":"2025-04-24T05:46:24.962840Z","shell.execute_reply":"2025-04-24T05:46:24.976367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Class Distribution","metadata":{"id":"Bw6OC0yFogP5"}},{"cell_type":"code","source":"# Count the occurrences of each label\nlabel_counts = df['DEI'].value_counts()\n\n# Create a bar plot\nplt.figure(figsize=(8, 5))\nsns.barplot(x=label_counts.index, y=label_counts.values, palette='viridis')\n\n# Customize the plot\nplt.title('Distribution of DEI Labels')\nplt.xlabel('Labels')\nplt.ylabel('Number of Tweets')\nplt.xticks(ticks=[0, 1], labels=['Non-DEI (0)', 'DEI (1)'])\nplt.ylim(0, max(label_counts.values) + 50)\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"id":"oZqf7X4AogP5","outputId":"043728df-68d5-4fbf-a4a0-1e5df4feb43e","execution":{"iopub.status.busy":"2025-04-24T05:46:24.978116Z","iopub.execute_input":"2025-04-24T05:46:24.978438Z","iopub.status.idle":"2025-04-24T05:46:25.222679Z","shell.execute_reply.started":"2025-04-24T05:46:24.978413Z","shell.execute_reply":"2025-04-24T05:46:25.221916Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Split the dataset into train, test and validation sets","metadata":{"id":"3UuxR5saogP7"}},{"cell_type":"code","source":"# Split the dataset\nfrom sklearn.model_selection import train_test_split\ntrain_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-04-24T05:46:25.223892Z","iopub.execute_input":"2025-04-24T05:46:25.224188Z","iopub.status.idle":"2025-04-24T05:46:25.234319Z","shell.execute_reply.started":"2025-04-24T05:46:25.224160Z","shell.execute_reply":"2025-04-24T05:46:25.233625Z"},"trusted":true,"id":"W8g6vGDUogP7"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print the size of each dataset\nprint(f\"Training set size: {train_df.shape[0]} samples\")\nprint(f\"Validation set size: {val_df.shape[0]} samples\")\nprint(f\"Test set size: {test_df.shape[0]} samples\")","metadata":{"trusted":true,"id":"r732w7otogP7","outputId":"aa791ee2-32ae-48b5-ad21-f58705b4c91d","execution":{"iopub.status.busy":"2025-04-24T05:46:25.235292Z","iopub.execute_input":"2025-04-24T05:46:25.235595Z","iopub.status.idle":"2025-04-24T05:46:25.245001Z","shell.execute_reply.started":"2025-04-24T05:46:25.235569Z","shell.execute_reply":"2025-04-24T05:46:25.244169Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define path for Model and Tokenizer","metadata":{"id":"LQeDZWCEogP7"}},{"cell_type":"code","source":"# Load the BERTweet model and tokenizer\nmodel_path = \"vinai/bertweet-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2025-04-24T05:46:25.246013Z","iopub.execute_input":"2025-04-24T05:46:25.246234Z","iopub.status.idle":"2025-04-24T05:46:30.674741Z","shell.execute_reply.started":"2025-04-24T05:46:25.246212Z","shell.execute_reply":"2025-04-24T05:46:30.673830Z"},"trusted":true,"id":"A3LrHfTzogP8","outputId":"12b0f652-98bf-479d-d823-54c664036b48"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenize the train, test and validation sets","metadata":{"id":"55UdvGdoogP8"}},{"cell_type":"code","source":"# Tokenization function\ndef tokenize(df):\n    return tokenizer(df['Tweet'].tolist(), padding='max_length', truncation=True, max_length=128, return_tensors='pt')","metadata":{"trusted":true,"id":"WsJ6PMbxogP8","execution":{"iopub.status.busy":"2025-04-24T05:46:30.675862Z","iopub.execute_input":"2025-04-24T05:46:30.676139Z","iopub.status.idle":"2025-04-24T05:46:30.680310Z","shell.execute_reply.started":"2025-04-24T05:46:30.676113Z","shell.execute_reply":"2025-04-24T05:46:30.679427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize the train, validation, and test data\ntrain_encoded = tokenize(train_df)\nval_encoded = tokenize(val_df)\ntest_encoded = tokenize(test_df)","metadata":{"trusted":true,"id":"bivdW05pogP8","execution":{"iopub.status.busy":"2025-04-24T05:46:30.681442Z","iopub.execute_input":"2025-04-24T05:46:30.681945Z","iopub.status.idle":"2025-04-24T05:46:31.258896Z","shell.execute_reply.started":"2025-04-24T05:46:30.681908Z","shell.execute_reply":"2025-04-24T05:46:31.258018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the labels (ensure they are tensor-compatible with PyTorch)\ntrain_labels = torch.tensor(train_df['DEI'].values)\nval_labels = torch.tensor(val_df['DEI'].values)\ntest_labels = torch.tensor(test_df['DEI'].values)","metadata":{"trusted":true,"id":"CU6oLICwogP8","execution":{"iopub.status.busy":"2025-04-24T05:46:31.260068Z","iopub.execute_input":"2025-04-24T05:46:31.260763Z","iopub.status.idle":"2025-04-24T05:46:31.274715Z","shell.execute_reply.started":"2025-04-24T05:46:31.260724Z","shell.execute_reply":"2025-04-24T05:46:31.274065Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the Model","metadata":{"id":"xjw7J7qfogP9"}},{"cell_type":"code","source":"# Load the BERTweet model for sequence classification\nmodel = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=2)  # 2 classes (DEI vs non-DEI)","metadata":{"trusted":true,"id":"d3-rcxVFogP9","outputId":"ff054f45-8da4-46d2-d8d9-46fd5f2309d4","execution":{"iopub.status.busy":"2025-04-24T05:46:31.275624Z","iopub.execute_input":"2025-04-24T05:46:31.275880Z","iopub.status.idle":"2025-04-24T05:46:34.491086Z","shell.execute_reply.started":"2025-04-24T05:46:31.275856Z","shell.execute_reply":"2025-04-24T05:46:34.490309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create a Custom Pytorch Dataset","metadata":{"id":"9tONADabogP9"}},{"cell_type":"code","source":"# Define the Hugging Face Dataset class\nclass DEIDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"trusted":true,"id":"TnT-oAYcogP-","execution":{"iopub.status.busy":"2025-04-24T05:46:34.492190Z","iopub.execute_input":"2025-04-24T05:46:34.492545Z","iopub.status.idle":"2025-04-24T05:46:34.498461Z","shell.execute_reply.started":"2025-04-24T05:46:34.492503Z","shell.execute_reply":"2025-04-24T05:46:34.497579Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the train, val, and test datasets\ntrain_dataset = DEIDataset(train_encoded, train_labels)\nval_dataset = DEIDataset(val_encoded, val_labels)\ntest_dataset = DEIDataset(test_encoded, test_labels)","metadata":{"trusted":true,"id":"Zm7c1a5UogP_","execution":{"iopub.status.busy":"2025-04-24T05:46:34.499576Z","iopub.execute_input":"2025-04-24T05:46:34.499845Z","iopub.status.idle":"2025-04-24T05:46:34.507845Z","shell.execute_reply.started":"2025-04-24T05:46:34.499804Z","shell.execute_reply":"2025-04-24T05:46:34.506995Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Set up the Training Parameters and Evaluation Metrics","metadata":{"id":"r369bn0RogQE"}},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions\n\n    # Convert 2D predictions to 1D by taking the argmax\n    if len(preds.shape) > 1 and preds.shape[1] > 1:\n        preds = np.argmax(preds, axis=1)\n\n    # Ensure preds and labels are 1D arrays\n    preds = preds.flatten()\n    labels = labels.flatten()\n\n    # Calculate metrics\n    accuracy = accuracy_score(labels, preds)\n    precision = precision_score(labels, preds)\n    recall = recall_score(labels, preds)\n    f1 = f1_score(labels, preds)\n    auc_score = roc_auc_score(labels, preds)\n\n    # Return as a dictionary\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1': f1,\n        'auc': auc_score\n    }","metadata":{"trusted":true,"id":"Fq_Qh0rzogRB","execution":{"iopub.status.busy":"2025-04-24T05:46:34.508932Z","iopub.execute_input":"2025-04-24T05:46:34.509183Z","iopub.status.idle":"2025-04-24T05:46:34.517597Z","shell.execute_reply.started":"2025-04-24T05:46:34.509159Z","shell.execute_reply":"2025-04-24T05:46:34.516733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # number of training epochs\n    per_device_train_batch_size=16,  # batch size for training\n    per_device_eval_batch_size=16,   # batch size for evaluation\n    warmup_steps=120,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.02,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    learning_rate = 5e-6,\n    logging_steps=10,\n    # Evaluate more frequently\n    evaluation_strategy=\"epoch\",     \n    eval_steps=50,                   \n    save_strategy=\"epoch\",\n    save_steps=50,\n    load_best_model_at_end=True,      # load the best model when training is finished\n     warmup_ratio=0.1,\n    # Add gradient clipping to prevent exploding gradients\n    max_grad_norm=1.0,\n    # Add label smoothing to prevent overconfidence\n    label_smoothing_factor=0.1,\n    # Add metric for model selection\n    metric_for_best_model=\"f1\",\n    greater_is_better=True\n    \n\n)","metadata":{"trusted":true,"id":"Z5MIzVQlogRC","outputId":"9da1821e-fda2-4129-f45e-520fbc0fccb2","execution":{"iopub.status.busy":"2025-04-24T05:46:34.518570Z","iopub.execute_input":"2025-04-24T05:46:34.518862Z","iopub.status.idle":"2025-04-24T05:46:34.598775Z","shell.execute_reply.started":"2025-04-24T05:46:34.518838Z","shell.execute_reply":"2025-04-24T05:46:34.598128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the Trainer\ntrainer = Trainer(\n    model=model,                         # the BERTweet model for sequence classification\n    args=training_args,                  # training arguments\n    train_dataset=train_dataset,         # training dataset\n    eval_dataset=val_dataset,            # validation dataset\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Add early stopping here\n\n\n)","metadata":{"trusted":true,"id":"G6JlR4jkogRF","execution":{"iopub.status.busy":"2025-04-24T05:46:34.599652Z","iopub.execute_input":"2025-04-24T05:46:34.599918Z","iopub.status.idle":"2025-04-24T05:46:35.040867Z","shell.execute_reply.started":"2025-04-24T05:46:34.599893Z","shell.execute_reply":"2025-04-24T05:46:35.039959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" trainer.train()","metadata":{"trusted":true,"id":"7HUXUUCDogRG","outputId":"14eaec5e-57dc-4fdf-b5c3-3d03c73f782c","execution":{"iopub.status.busy":"2025-04-24T05:52:17.720124Z","iopub.execute_input":"2025-04-24T05:52:17.720497Z","iopub.status.idle":"2025-04-24T05:53:06.065967Z","shell.execute_reply.started":"2025-04-24T05:52:17.720464Z","shell.execute_reply":"2025-04-24T05:53:06.065207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on the test set\nresults = trainer.evaluate(test_dataset)","metadata":{"trusted":true,"id":"5GQFDxhsogRG","outputId":"89555566-ac77-4cf3-9bd7-105164c5dcce","execution":{"iopub.status.busy":"2025-04-24T06:04:16.641368Z","iopub.execute_input":"2025-04-24T06:04:16.642052Z","iopub.status.idle":"2025-04-24T06:04:17.048306Z","shell.execute_reply.started":"2025-04-24T06:04:16.642020Z","shell.execute_reply":"2025-04-24T06:04:17.047397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(results)","metadata":{"trusted":true,"id":"YVTUzPswogRH","outputId":"1bfc54c1-51d9-4573-a3a5-9b4cfdb6a436","execution":{"iopub.status.busy":"2025-04-24T06:04:19.325280Z","iopub.execute_input":"2025-04-24T06:04:19.326081Z","iopub.status.idle":"2025-04-24T06:04:19.330326Z","shell.execute_reply.started":"2025-04-24T06:04:19.326048Z","shell.execute_reply":"2025-04-24T06:04:19.329417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Test Accuracy: {results['eval_accuracy']:.4f}\")\nprint(f\"Test Precision: {results['eval_precision']:.4f}\")\nprint(f\"Test Recall: {results['eval_recall']:.4f}\")\nprint(f\"Test F1 Score: {results['eval_f1']:.4f}\")\nprint(f\"Test AUC Score: {results['eval_auc']:.4f}\")","metadata":{"trusted":true,"id":"m0bLKwBmogRH","outputId":"2ed23d9a-2cf9-47ca-b0a1-4606f37654f7","execution":{"iopub.status.busy":"2025-04-24T06:04:23.377893Z","iopub.execute_input":"2025-04-24T06:04:23.378227Z","iopub.status.idle":"2025-04-24T06:04:23.383125Z","shell.execute_reply.started":"2025-04-24T06:04:23.378199Z","shell.execute_reply":"2025-04-24T06:04:23.382322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate predictions on the test dataset\npredictions = trainer.predict(test_dataset)","metadata":{"trusted":true,"id":"lhaayB-YogRK","outputId":"9cf800d5-2f76-40db-e6a5-a8cdca761a1f","execution":{"iopub.status.busy":"2025-04-24T06:04:28.409514Z","iopub.execute_input":"2025-04-24T06:04:28.409919Z","iopub.status.idle":"2025-04-24T06:04:28.819311Z","shell.execute_reply.started":"2025-04-24T06:04:28.409890Z","shell.execute_reply":"2025-04-24T06:04:28.818400Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the predicted labels and true labels\npredicted_labels = np.argmax(predictions.predictions, axis=-1)\ntrue_labels = test_labels.numpy()","metadata":{"trusted":true,"id":"L2AuLZcKogRL","execution":{"iopub.status.busy":"2025-04-24T06:04:28.820674Z","iopub.execute_input":"2025-04-24T06:04:28.820937Z","iopub.status.idle":"2025-04-24T06:04:28.825063Z","shell.execute_reply.started":"2025-04-24T06:04:28.820913Z","shell.execute_reply":"2025-04-24T06:04:28.824149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(true_labels, predicted_labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Non-DEI', 'DEI'],\n            yticklabels=['Non-DEI', 'DEI'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"id":"cq-sM4H6ogRL","outputId":"4c4dface-e53f-4968-acfc-0b033fd54cb4","execution":{"iopub.status.busy":"2025-04-24T06:04:28.826181Z","iopub.execute_input":"2025-04-24T06:04:28.826735Z","iopub.status.idle":"2025-04-24T06:04:29.079138Z","shell.execute_reply.started":"2025-04-24T06:04:28.826697Z","shell.execute_reply":"2025-04-24T06:04:29.078307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Save the Model","metadata":{"id":"rZWmawC0ogRN"}},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained('./fine_tuned_bert')\ntokenizer.save_pretrained('./fine_tuned_bert')","metadata":{"trusted":true,"id":"pV2zJpmOogRN","outputId":"2bae4d2e-5891-4297-9390-739c67b6f55a","execution":{"iopub.status.busy":"2025-04-24T06:04:29.081574Z","iopub.execute_input":"2025-04-24T06:04:29.082112Z","iopub.status.idle":"2025-04-24T06:04:30.370463Z","shell.execute_reply.started":"2025-04-24T06:04:29.082083Z","shell.execute_reply":"2025-04-24T06:04:30.369575Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load and Prepare Unseen Dataset","metadata":{"id":"YYQkG1vmogRO"}},{"cell_type":"code","source":"directory_main = '/kaggle/input/tweets-main/Tweets'\ndirectory_engg = '/kaggle/input/engineering-tweets-dataset/Output Data [Engineering]/Output Data [Engineering]'\ndirectory_business = '/kaggle/input/tweets-business/Output Data [Business]-20241121T042244Z-001/Output Data [Business]'\ndirectory_law = '/kaggle/input/tweets-law/Output Data [Law]'\ndirectory_med = '/kaggle/input/tweets-med/Output Data [Med]'","metadata":{"trusted":true,"id":"f8SYSBv4ogRR","execution":{"iopub.status.busy":"2025-04-24T06:04:30.371430Z","iopub.execute_input":"2025-04-24T06:04:30.371689Z","iopub.status.idle":"2025-04-24T06:04:30.375670Z","shell.execute_reply.started":"2025-04-24T06:04:30.371664Z","shell.execute_reply":"2025-04-24T06:04:30.374841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_dataset(directory):\n    \n    all_df_list = []\n\n    for filename in os.listdir(directory):\n        df = pd.read_csv(os.path.join(directory, filename))\n        all_df_list.append(df)\n\n    return pd.concat(all_df_list, axis = 0, ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:04:30.377078Z","iopub.execute_input":"2025-04-24T06:04:30.377409Z","iopub.status.idle":"2025-04-24T06:04:30.387481Z","shell.execute_reply.started":"2025-04-24T06:04:30.377375Z","shell.execute_reply":"2025-04-24T06:04:30.386756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tweets_main = create_dataset(directory_main)\ntweets_engg = create_dataset(directory_engg)\ntweets_business = create_dataset(directory_business)\ntweets_law = create_dataset(directory_law)\ntweets_med = create_dataset(directory_med)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:04:30.388495Z","iopub.execute_input":"2025-04-24T06:04:30.388820Z","iopub.status.idle":"2025-04-24T06:05:51.678201Z","shell.execute_reply.started":"2025-04-24T06:04:30.388786Z","shell.execute_reply":"2025-04-24T06:05:51.677200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset = pd.concat([tweets_main, tweets_engg, tweets_business, tweets_law, tweets_med], axis = 0, ignore_index = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:51.680591Z","iopub.execute_input":"2025-04-24T06:05:51.680867Z","iopub.status.idle":"2025-04-24T06:05:57.538576Z","shell.execute_reply.started":"2025-04-24T06:05:51.680841Z","shell.execute_reply":"2025-04-24T06:05:57.537452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset.shape","metadata":{"trusted":true,"id":"3TK4_RQgogRT","outputId":"b81a40b9-f8e2-4e36-d241-82cae7ed3863","execution":{"iopub.status.busy":"2025-04-24T06:05:57.540008Z","iopub.execute_input":"2025-04-24T06:05:57.540588Z","iopub.status.idle":"2025-04-24T06:05:57.547900Z","shell.execute_reply.started":"2025-04-24T06:05:57.540547Z","shell.execute_reply":"2025-04-24T06:05:57.546888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset.head()","metadata":{"trusted":true,"id":"Qv52c4qyogRV","outputId":"d069721e-2cbd-4d74-d78e-52291f2176ef","execution":{"iopub.status.busy":"2025-04-24T06:05:57.551892Z","iopub.execute_input":"2025-04-24T06:05:57.552213Z","iopub.status.idle":"2025-04-24T06:05:57.579091Z","shell.execute_reply.started":"2025-04-24T06:05:57.552172Z","shell.execute_reply":"2025-04-24T06:05:57.578052Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load the Saved Model and Tokenizer","metadata":{"id":"X9glgvYCogRX"}},{"cell_type":"code","source":"# Load the model and tokenizer\nmodel_path = './fine_tuned_bert'\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nloaded_model = AutoModelForSequenceClassification.from_pretrained(model_path)","metadata":{"trusted":true,"id":"qtwFzl3SogRX","outputId":"cd9b3c85-27f4-4250-8d1e-5abb5edd3453","execution":{"iopub.status.busy":"2025-04-24T06:05:57.580156Z","iopub.execute_input":"2025-04-24T06:05:57.580486Z","iopub.status.idle":"2025-04-24T06:05:57.773614Z","shell.execute_reply.started":"2025-04-24T06:05:57.580460Z","shell.execute_reply":"2025-04-24T06:05:57.772700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"id":"bJpf-k4X-wck","outputId":"6d7879a0-f05b-4750-c8be-5c4f8c337a93","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.774786Z","iopub.execute_input":"2025-04-24T06:05:57.775235Z","iopub.status.idle":"2025-04-24T06:05:57.780680Z","shell.execute_reply.started":"2025-04-24T06:05:57.775197Z","shell.execute_reply":"2025-04-24T06:05:57.779654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TweetTokenizer:\n\n  def __init__(self, model_path: str, max_length: int = 128):\n        \"\"\"\n        Initialize tokenizer with specific configurations\n\n        Args:\n            model_path (str): Path where model and tokenizer were saved\n            max_length (int): Maximum sequence length for tokenization\n        \"\"\"\n        # Load the pre-trained tokenizer from the saved path\n        # This ensures we use the exact tokenizer configuration from fine-tuning\n        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n        # Set maximum sequence length\n        self.max_length = max_length\n\n        # Determine optimal number of CPU cores for parallel processing\n        self.num_cores = multiprocessing.cpu_count()\n\n  def batch_tokenize(self, tweets: List[str]) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Tokenize tweets in batches using multiprocessing\n\n    Args:\n    tweets (List[str]): List of tweet texts to tokenize\n\n    Returns:\n    Dict containing tokenized inputs\n    \"\"\"\n    # Use multiprocessing to speed up tokenization\n    with multiprocessing.Pool(self.num_cores) as pool:\n      # Map tokenization across multiple CPU cores\n      tokenized_inputs = pool.map(self._tokenize_single, tweets)\n\n      # Convert list of dictionaries to tensors\n      return self._convert_to_tensors(tokenized_inputs)\n\n\n\n  def _tokenize_single(self, tweet: str) -> Dict[str, List[int]]:\n    \"\"\"\n    Tokenize a single tweet\n\n    Args:\n    tweet (str): Single tweet text\n\n    Returns:\n    Tokenized representation of the tweet\n    \"\"\"\n    # Perform tokenization with specific parameters\n    encoding = self.tokenizer(\n            tweet,\n            truncation=True,  # Cut off sequences longer than max_length\n            padding='max_length',  # Pad to max_length\n            max_length=self.max_length,\n            return_tensors=None  # Return as lists for multiprocessing\n        )\n    return encoding\n\n\n\n  def _convert_to_tensors(self, tokenized_inputs: List[Dict]) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Convert tokenized inputs to PyTorch tensors\n\n    Args:\n    tokenized_inputs (List[Dict]): List of tokenized tweet representations\n\n    Returns:\n    Dictionary of tensors\n    \"\"\"\n    return {\n        'input_ids': torch.tensor([x['input_ids'] for x in tokenized_inputs]),\n        'attention_mask': torch.tensor([x['attention_mask'] for x in tokenized_inputs])\n        }","metadata":{"id":"82R4rKo1-wZE","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.781945Z","iopub.execute_input":"2025-04-24T06:05:57.782252Z","iopub.status.idle":"2025-04-24T06:05:57.794723Z","shell.execute_reply.started":"2025-04-24T06:05:57.782215Z","shell.execute_reply":"2025-04-24T06:05:57.790972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TweetDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        \"\"\"\n        Create a PyTorch Dataset for tweets\n\n        Args:\n            dataframe (pd.DataFrame): DataFrame containing tweets\n            tokenizer (TweetTokenizer): Custom tokenizer instance\n        \"\"\"\n        self.dataframe = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n        # Precompute tweet texts to avoid repeated DataFrame column access\n        self.tweets = self.dataframe['Tweet'].tolist()\n\n    def __len__(self) -> int:\n        \"\"\"\n        Return total number of tweets in the dataset\n        \"\"\"\n        return len(self.tweets)\n\n    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Tokenize a single tweet\n\n        Returns:\n            Dict of tokenized inputs\n        \"\"\"\n        # Tokenize single tweet\n        encoding = self.tokenizer(\n            self.tweets[idx],\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze()\n        }","metadata":{"id":"TWB6MkDDD4Ti","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.795906Z","iopub.execute_input":"2025-04-24T06:05:57.796668Z","iopub.status.idle":"2025-04-24T06:05:57.812568Z","shell.execute_reply.started":"2025-04-24T06:05:57.796635Z","shell.execute_reply":"2025-04-24T06:05:57.811389Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dataframe_chunk_generator(unseen_dataset, chunk_size=100000):\n    \"\"\"\n    Generator that yields chunks of the DataFrame\n\n    Args:\n        unseen_dataset (pd.DataFrame): Concatenated DataFrame\n        chunk_size (int): Number of rows per chunk\n\n    Yields:\n        DataFrame chunks\n    \"\"\"\n    for i in range(0, len(unseen_dataset), chunk_size):\n        yield unseen_dataset.iloc[i:i+chunk_size]","metadata":{"id":"483MkRxnD4N7","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.813492Z","iopub.execute_input":"2025-04-24T06:05:57.813765Z","iopub.status.idle":"2025-04-24T06:05:57.821956Z","shell.execute_reply.started":"2025-04-24T06:05:57.813739Z","shell.execute_reply":"2025-04-24T06:05:57.821128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_large_dataset_generator(unseen_dataset, model, tokenizer,  output_dir, checkpoint_prefix, chunk_size, batch_size):\n    \"\"\"\n    Process large dataset using generator-based approach\n    \n    Args:\n        unseen_dataset (pd.DataFrame): Concatenated DataFrame\n        model (torch.nn.Module): Trained model\n        tokenizer (Tokenizer): Tokenization object\n        chunk_size (int): Number of rows per chunk\n        batch_size (int): Number of samples per batch\n    \n    Returns:\n        List of all predictions\n    \"\"\"\n    # Ensure output directory exists\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # List to store all predictions\n    all_predictions = []\n\n    # Calculate total number of chunks\n    total_chunks = (len(unseen_dataset) + chunk_size - 1) // chunk_size  \n\n    # Use the generator to process chunks\n    for chunk_index, chunk in enumerate(dataframe_chunk_generator(unseen_dataset, chunk_size), 1):\n\n        # Define the checkpoint file path for the current chunk\n        checkpoint_file = os.path.join(output_dir, f\"{checkpoint_prefix}{chunk_index}.npy\")\n\n        # Skip if checkpoint already exists\n        if os.path.exists(checkpoint_file):\n            print(f\"Skipping chunk {chunk_index}, already processed.\")\n            continue\n            \n        print(f\"Processing chunk {chunk_index}\")\n        \n        # Create dataset for current chunk\n        dataset = TweetDataset(chunk, tokenizer)\n        \n        # Create DataLoader\n        dataloader = DataLoader(\n            dataset, \n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=min(4, os.cpu_count()),\n            pin_memory=torch.cuda.is_available()\n        )\n        \n        # Inference for current chunk\n        chunk_predictions = []\n        with torch.no_grad():\n            for batch in  tqdm(dataloader, desc=f\"Chunk {chunk_index}/{total_chunks}\", leave=False):\n                # Move inputs to appropriate device\n                input_ids = batch['input_ids'].to(model.device)\n                attention_mask = batch['attention_mask'].to(model.device)\n                \n                # Model prediction\n                outputs = model(\n                    input_ids=input_ids, \n                    attention_mask=attention_mask\n                )\n                \n                # Process predictions (adjust based on your model output)\n                predictions = torch.softmax(outputs.logits, dim=1)\n                \n                # Convert to numpy and extend predictions\n                chunk_predictions.extend(predictions.cpu().numpy())\n                \n                # Clear GPU memory\n                del input_ids, attention_mask, outputs\n                torch.cuda.empty_cache()\n\n        \n        # Accumulate chunk predictions\n        all_predictions.extend(chunk_predictions)\n\n        # Indicate that the current chunk has finished processing\n        print(colored(f\"Finished processing chunk {chunk_index}/{total_chunks}\", \"green\"))\n         \n        # Save predictions for the current chunk\n        np.save(checkpoint_file, chunk_predictions)\n        print(f\"\\033[95mSaved predictions for chunk {chunk_index} to {checkpoint_file}\\033[0m\")\n\n    print(\"\\033[92mAll chunks processed successfully!\\033[0m\")\n    \n    return all_predictions","metadata":{"id":"q1zD4cS2D4LY","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.823281Z","iopub.execute_input":"2025-04-24T06:05:57.823664Z","iopub.status.idle":"2025-04-24T06:05:57.834327Z","shell.execute_reply.started":"2025-04-24T06:05:57.823627Z","shell.execute_reply":"2025-04-24T06:05:57.833517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%javascript\nfunction keepNotebookAwake() {\n    var element = document.querySelector('body');\n    var event = new MouseEvent('mousemove', {\n        'view': window,\n        'bubbles': true,\n        'cancelable': true\n    });\n    element.dispatchEvent(event);\n}\n\n// Run this every 5 minutes\nsetInterval(keepNotebookAwake, 300000);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.835408Z","iopub.execute_input":"2025-04-24T06:05:57.835744Z","iopub.status.idle":"2025-04-24T06:05:57.847467Z","shell.execute_reply.started":"2025-04-24T06:05:57.835710Z","shell.execute_reply":"2025-04-24T06:05:57.846477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Process the entire dataset\npredictions = process_large_dataset_generator(\n    unseen_dataset, \n    model, \n    tokenizer,\n    output_dir=\"checkpoints/\",\n    checkpoint_prefix=\"predictions_chunk_\", \n    chunk_size=100000, \n    batch_size=64\n)","metadata":{"id":"SJvJhKAQ-wNC","outputId":"4ac07cbc-efa2-4a91-c90a-942430ad18f5","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:05:57.848487Z","iopub.execute_input":"2025-04-24T06:05:57.848951Z","iopub.status.idle":"2025-04-24T15:01:58.378134Z","shell.execute_reply.started":"2025-04-24T06:05:57.848906Z","shell.execute_reply":"2025-04-24T15:01:58.376957Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"binary_labels = []\n\nfor pred in predictions:\n    # Label is 1 if probability of class 1 is higher than a threshold\n    label = 1 if pred[1] >= 0.8 else 0\n    binary_labels.append(label)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:01:58.379734Z","iopub.execute_input":"2025-04-24T15:01:58.380052Z","iopub.status.idle":"2025-04-24T15:02:11.244102Z","shell.execute_reply.started":"2025-04-24T15:01:58.380022Z","shell.execute_reply":"2025-04-24T15:02:11.243145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_labels = []\nconfidence_scores = []\nfor pred in predictions:\n    predicted_labels.append(np.argmax(pred))\n    confidence_scores.append(np.max(pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:02:11.245213Z","iopub.execute_input":"2025-04-24T15:02:11.245495Z","iopub.status.idle":"2025-04-24T15:02:50.537375Z","shell.execute_reply.started":"2025-04-24T15:02:11.245468Z","shell.execute_reply":"2025-04-24T15:02:50.536657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset['Confidence_Score'] = confidence_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:02:50.538447Z","iopub.execute_input":"2025-04-24T15:02:50.538739Z","iopub.status.idle":"2025-04-24T15:02:52.512669Z","shell.execute_reply.started":"2025-04-24T15:02:50.538713Z","shell.execute_reply":"2025-04-24T15:02:52.511756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add predictions to the unseen dataframe\nunseen_dataset['Predicted_DEI'] = predicted_labels","metadata":{"trusted":true,"id":"IlTpp0iBogRe","execution":{"iopub.status.busy":"2025-04-24T15:08:25.844893Z","iopub.execute_input":"2025-04-24T15:08:25.845526Z","iopub.status.idle":"2025-04-24T15:08:38.707062Z","shell.execute_reply.started":"2025-04-24T15:08:25.845491Z","shell.execute_reply":"2025-04-24T15:08:38.706067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_250k = unseen_dataset.sample(n=250000, random_state = 42)\nsample_250k.to_csv('sample_250k.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:02:38.416080Z","iopub.execute_input":"2025-04-24T16:02:38.416494Z","iopub.status.idle":"2025-04-24T16:02:42.687982Z","shell.execute_reply.started":"2025-04-24T16:02:38.416463Z","shell.execute_reply":"2025-04-24T16:02:42.687268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_20k = unseen_dataset.sample(n=20000, random_state = 42)\nsample_20k.to_csv('sample_20k.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:05:13.695950Z","iopub.execute_input":"2025-04-24T16:05:13.696787Z","iopub.status.idle":"2025-04-24T16:05:14.307872Z","shell.execute_reply.started":"2025-04-24T16:05:13.696754Z","shell.execute_reply":"2025-04-24T16:05:14.307146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset.head()","metadata":{"trusted":true,"id":"XYdYWDUoogRe","execution":{"iopub.status.busy":"2025-04-24T15:03:05.526503Z","iopub.execute_input":"2025-04-24T15:03:05.526768Z","iopub.status.idle":"2025-04-24T15:03:05.549109Z","shell.execute_reply.started":"2025-04-24T15:03:05.526742Z","shell.execute_reply":"2025-04-24T15:03:05.548195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unseen_dataset['Predicted_DEI'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:08:15.642643Z","iopub.execute_input":"2025-04-24T15:08:15.642998Z","iopub.status.idle":"2025-04-24T15:08:15.689862Z","shell.execute_reply.started":"2025-04-24T15:08:15.642968Z","shell.execute_reply":"2025-04-24T15:08:15.688934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the predictions to a new CSV file\nunseen_dataset.to_csv('/kaggle/working/predicted_unseen_data.csv', index=False)","metadata":{"trusted":true,"id":"KTGrZ274ogRf","execution":{"iopub.status.busy":"2025-04-24T15:03:05.602971Z","iopub.execute_input":"2025-04-24T15:03:05.603227Z","iopub.status.idle":"2025-04-24T15:04:33.754440Z","shell.execute_reply.started":"2025-04-24T15:03:05.603203Z","shell.execute_reply":"2025-04-24T15:04:33.753659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the unseen data with predictions\npredicted_df = unseen_dataset.copy()","metadata":{"trusted":true,"id":"-U-TVeYtogRf","execution":{"iopub.status.busy":"2025-04-24T15:04:33.755508Z","iopub.execute_input":"2025-04-24T15:04:33.755791Z","iopub.status.idle":"2025-04-24T15:04:41.384634Z","shell.execute_reply.started":"2025-04-24T15:04:33.755766Z","shell.execute_reply":"2025-04-24T15:04:41.383831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizations","metadata":{"id":"OeDY2I3MogRj"}},{"cell_type":"markdown","source":"## Trend of DEI Tweets over time","metadata":{"id":"9PnNd-USogRw"}},{"cell_type":"code","source":"# Filter out non-date entries, including \"0\"\npredicted_df = predicted_df[predicted_df[\"Date\"].astype(str).str.isnumeric() == False]","metadata":{"trusted":true,"id":"qJdYQWKJogRx","execution":{"iopub.status.busy":"2025-04-24T15:07:12.929586Z","iopub.execute_input":"2025-04-24T15:07:12.930257Z","iopub.status.idle":"2025-04-24T15:07:54.294709Z","shell.execute_reply.started":"2025-04-24T15:07:12.930224Z","shell.execute_reply":"2025-04-24T15:07:54.293964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_df[\"Date\"] = pd.to_datetime(predicted_df[\"Date\"])\npredicted_df[\"Year\"] = predicted_df[\"Date\"].dt.year","metadata":{"trusted":true,"id":"XWi7Rpn5ogRy","execution":{"iopub.status.busy":"2025-04-24T15:07:57.048010Z","iopub.execute_input":"2025-04-24T15:07:57.048800Z","iopub.status.idle":"2025-04-24T15:07:57.449877Z","shell.execute_reply.started":"2025-04-24T15:07:57.048767Z","shell.execute_reply":"2025-04-24T15:07:57.449077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_dei_tweets_by_year = predicted_df[predicted_df[\"Predicted_DEI\"]==1].groupby(\"Year\").size().reset_index(name=\"DEI_Tweet_Count\")","metadata":{"trusted":true,"id":"BMQtenePogRz","execution":{"iopub.status.busy":"2025-04-24T15:08:00.448893Z","iopub.execute_input":"2025-04-24T15:08:00.449556Z","iopub.status.idle":"2025-04-24T15:08:00.938552Z","shell.execute_reply.started":"2025-04-24T15:08:00.449523Z","shell.execute_reply":"2025-04-24T15:08:00.937832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a DataFrame with all years from 2010 to 2022\nyears = pd.DataFrame({'Year': list(range(2010, 2023))})\n\n# Merge with the original data (predicted_dei_tweets_by_year) to ensure all years are present\npredicted_dei_tweets_by_year = years.merge(predicted_dei_tweets_by_year, on='Year', how='left')\n\n# Fill missing DEI tweet counts with 0\npredicted_dei_tweets_by_year['DEI_Tweet_Count'].fillna(0, inplace=True)\n\n# Plotting the line chart\nplt.figure(figsize=(9, 5))  # Set figure size\nplt.plot(predicted_dei_tweets_by_year['Year'], \n         predicted_dei_tweets_by_year['DEI_Tweet_Count'], \n         marker='o',  # Add markers at each point\n         label='DEI Tweets Count')\n\n# Customize layout (axis labels, title, etc.)\nplt.title('Predicted DEI-Related Tweets Over Time', fontsize=14, loc='center')  # Center the title\nplt.xlabel('Year', fontsize=12)\nplt.ylabel('DEI Tweets Count', fontsize=12)\nplt.grid(visible=True, linestyle='--', alpha=0.7)  # Add a grid for better readability\nplt.xticks(predicted_dei_tweets_by_year['Year'], rotation=45)  # Rotate x-axis labels if needed\nplt.tight_layout()  # Adjust layout to prevent clipping\nplt.legend()  # Add legend\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:08:03.890573Z","iopub.execute_input":"2025-04-24T15:08:03.891390Z","iopub.status.idle":"2025-04-24T15:08:04.230021Z","shell.execute_reply.started":"2025-04-24T15:08:03.891328Z","shell.execute_reply":"2025-04-24T15:08:04.229119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_dei_tweets_by_year","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T15:04:53.891480Z","iopub.execute_input":"2025-04-24T15:04:53.892103Z","iopub.status.idle":"2025-04-24T15:04:53.900369Z","shell.execute_reply.started":"2025-04-24T15:04:53.892061Z","shell.execute_reply":"2025-04-24T15:04:53.899519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hbcu_list = ['Florida A&M University',\n'North Carolina Agricultural & Technical State University'\n'Howard University',\n'Spelman College',\n'Morgan State University']","metadata":{"trusted":true,"id":"ih0u9rqeogR2","execution":{"iopub.status.busy":"2025-04-24T15:04:53.901482Z","iopub.execute_input":"2025-04-24T15:04:53.901782Z","iopub.status.idle":"2025-04-24T15:04:53.910809Z","shell.execute_reply.started":"2025-04-24T15:04:53.901756Z","shell.execute_reply":"2025-04-24T15:04:53.909899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uni_df = predicted_df[(predicted_df[\"Predicted_DEI\"]==1) & (predicted_df[\"University\"]==\"Florida A&M University\")]\nuni_df['Tweet'].sample(n=10).tolist()","metadata":{"trusted":true,"id":"FQvsFIZvogR3","execution":{"iopub.status.busy":"2025-04-24T15:04:53.912016Z","iopub.execute_input":"2025-04-24T15:04:53.912627Z","iopub.status.idle":"2025-04-24T15:04:54.449048Z","shell.execute_reply.started":"2025-04-24T15:04:53.912590Z","shell.execute_reply":"2025-04-24T15:04:54.448113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uni_df.shape","metadata":{"trusted":true,"id":"SKzpIZWzogR3","execution":{"iopub.status.busy":"2025-04-24T15:04:54.450301Z","iopub.execute_input":"2025-04-24T15:04:54.450964Z","iopub.status.idle":"2025-04-24T15:04:54.456530Z","shell.execute_reply.started":"2025-04-24T15:04:54.450923Z","shell.execute_reply":"2025-04-24T15:04:54.455572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of selected universities\nselected_universities = ['Harvard University', 'Yale University', 'Columbia University', 'Massachusetts Institute of Technology (MIT)', 'Stanford University']  # Add your universities here\n\n# Filter data for selected universities and DEI tweets\nfiltered_df = predicted_df[(predicted_df['University'].isin(selected_universities)) &\n                           (predicted_df['Predicted_DEI'] == 1)]\n\n# Group by university and count DEI tweets\ndei_tweet_counts = filtered_df.groupby('University').size().reset_index(name='DEI_Tweet_Count')\n\n# Print each university name and its DEI tweet count\nfor index, row in dei_tweet_counts.iterrows():\n    print(f\"University: {row['University']}, DEI Tweet Count: {row['DEI_Tweet_Count']}\")","metadata":{"trusted":true,"id":"q6upj5mLogR4","execution":{"iopub.status.busy":"2025-04-24T15:04:54.457655Z","iopub.execute_input":"2025-04-24T15:04:54.457924Z","iopub.status.idle":"2025-04-24T15:04:54.764363Z","shell.execute_reply.started":"2025-04-24T15:04:54.457901Z","shell.execute_reply":"2025-04-24T15:04:54.763530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Filter for DEI tweets only\ndei_tweets = predicted_df[predicted_df['Predicted_DEI'] == 1]\n\n# Get top universities by total DEI tweet count\ntop_unis = (dei_tweets.groupby('University')\n            .size()\n            .nlargest(5)\n            .index\n            .tolist())\n\n# Filter data for top universities\ntop_unis_df = dei_tweets[dei_tweets['University'].isin(top_unis)]\n\n# Calculate yearly DEI tweets for each university\nyearly_dei = (top_unis_df.groupby(['Year', 'University'])\n              .size()\n              .unstack(fill_value=0)  # Create a wide format with years as index and universities as columns\n              .reset_index())\n\n# Set 'Year' as index for the stacked bar chart\nyearly_dei.set_index('Year', inplace=True)\n\n# Create a stacked bar plot\nplt.figure(figsize=(12, 6))\nyearly_dei.plot(kind='bar', stacked=True, cmap='tab10', ax=plt.gca())\n\n# Customize the plot\nplt.title('Top 5 Universities DEI Tweet Counts Over Years', size=16)\nplt.xlabel('Year', size=12)\nplt.ylabel('Number of DEI Tweets', size=12)\nplt.xticks(rotation=45)  # Rotate x-axis labels for better readability\nplt.legend(title='University', bbox_to_anchor=(1.05, 1), loc='upper left')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"id":"5JqNe2h-ogR5","execution":{"iopub.status.busy":"2025-04-24T15:04:54.765446Z","iopub.execute_input":"2025-04-24T15:04:54.765737Z","iopub.status.idle":"2025-04-24T15:04:55.653076Z","shell.execute_reply.started":"2025-04-24T15:04:54.765711Z","shell.execute_reply":"2025-04-24T15:04:55.652179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport plotly.graph_objects as go\n\n# Filter for DEI tweets only\ndei_tweets = predicted_df[predicted_df['Predicted_DEI'] == 1]\n\n# Get top universities by total DEI tweet count\ntop_unis = (dei_tweets.groupby('University')\n            .size()\n            .nlargest(10)\n            .index\n            .tolist())\n\n# Filter data for top universities\ntop_unis_df = dei_tweets[dei_tweets['University'].isin(top_unis)]\n\n# Calculate yearly DEI tweets for each university\nyearly_dei = (top_unis_df.groupby(['Year', 'University'])\n              .size()\n              .unstack(fill_value=0))  # Create a wide format with years as index and universities as columns\n\n# Create a stacked bar chart\nfig = go.Figure()\n\n# Add a bar for each university\nfor uni in yearly_dei.columns:\n    fig.add_trace(go.Bar(\n        x=yearly_dei.index,\n        y=yearly_dei[uni],\n        name=uni,\n        hoverinfo='y+name',\n        marker=dict(line=dict(width=0))\n    ))\n\n# Update layout for stacked bar chart\nfig.update_layout(\n    title='Top 5 Universities DEI Tweet Counts Over Years',\n    xaxis_title='Year',\n    yaxis_title='Number of DEI Tweets',\n    barmode='stack',\n    legend_title='University'\n)\n\n# Show the plot\nfig.show()","metadata":{"trusted":true,"id":"9BOmKXKWogR6","execution":{"iopub.status.busy":"2025-04-24T15:04:55.654160Z","iopub.execute_input":"2025-04-24T15:04:55.654459Z","iopub.status.idle":"2025-04-24T15:04:56.624779Z","shell.execute_reply.started":"2025-04-24T15:04:55.654433Z","shell.execute_reply":"2025-04-24T15:04:56.623917Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### DEI Trend Over the Years in HBCUs","metadata":{"id":"C3-jiyqIogR7"}},{"cell_type":"code","source":"# List of selected universities\nselected_universities = ['Florida A&M University', 'Howard University', 'Spelman College',\n                         'Morgan State University', 'North Carolina Agricultural and Technical State University']\n\n# Filter data for selected universities and DEI tweets\nfiltered_df = predicted_df[(predicted_df['University'].isin(selected_universities)) &\n                           (predicted_df['Predicted_DEI'] == 1)]\n\n# Group by university and count DEI tweets\ndei_tweet_counts = filtered_df.groupby('University').size().reset_index(name='DEI_Tweet_Count')\n\n# Print each university name and its DEI tweet count\nfor index, row in dei_tweet_counts.iterrows():\n    print(f\"University: {row['University']}, DEI Tweet Count: {row['DEI_Tweet_Count']}\")","metadata":{"trusted":true,"id":"6JIwDTBEogR7","execution":{"iopub.status.busy":"2025-04-24T15:04:56.625991Z","iopub.execute_input":"2025-04-24T15:04:56.626376Z","iopub.status.idle":"2025-04-24T15:04:56.962610Z","shell.execute_reply.started":"2025-04-24T15:04:56.626316Z","shell.execute_reply":"2025-04-24T15:04:56.961647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Percentage of DEI Tweet Counts in HBCUs","metadata":{"id":"ChzFzTNqogR8"}},{"cell_type":"markdown","source":"","metadata":{"id":"R3kPL1H9ogSB"}},{"cell_type":"code","source":"# Filter data for top universities\ntop_unis_df = dei_tweets[dei_tweets['University'].isin(selected_universities)]\n\n# Calculate yearly DEI tweets for each university\nyearly_dei = (top_unis_df.groupby(['Year', 'University'])\n              .size()\n              .unstack(fill_value=0)  # Create a wide format with years as index and universities as columns\n              .reset_index())\n\n# Calculate yearly DEI tweets for each university\nyearly_dei = (top_unis_df.groupby(['Year', 'University'])\n              .size()\n              .unstack(fill_value=0))  # Create a wide format with years as index and universities as columns\n\n# Create a stacked bar chart\nfig = go.Figure()\n\n# Add a bar for each university\nfor uni in yearly_dei.columns:\n    fig.add_trace(go.Bar(\n        x=yearly_dei.index,\n        y=yearly_dei[uni],\n        name=uni,\n        hoverinfo='y+name',\n        marker=dict(line=dict(width=0))\n    ))\n\n# Update layout for stacked bar chart\nfig.update_layout(\n    title='HBCU DEI Tweet Counts Over Years',\n    xaxis_title='Year',\n    yaxis_title='Number of DEI Tweets',\n    barmode='stack',\n    legend_title='University'\n)\n\n# Show the plot\nfig.show()","metadata":{"trusted":true,"id":"qGMI6JWpogSB","execution":{"iopub.status.busy":"2025-04-24T15:04:56.963835Z","iopub.execute_input":"2025-04-24T15:04:56.964184Z","iopub.status.idle":"2025-04-24T15:04:57.035069Z","shell.execute_reply.started":"2025-04-24T15:04:56.964146Z","shell.execute_reply":"2025-04-24T15:04:57.034315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grouped_df = predicted_df.groupby(['University', 'Year'])['Predicted_DEI'].sum().reset_index()\n\n# Step 2: Get the top 5 universities with the highest total DEI tweet counts\ntop_unis = grouped_df.groupby('University')['Predicted_DEI'].sum().nlargest(5).index\n\n# Step 3: Filter the DataFrame for only those top 5 universities\nfiltered_df = grouped_df[grouped_df['University'].isin(top_unis)]","metadata":{"trusted":true,"id":"9UltyLRRogSC","execution":{"iopub.status.busy":"2025-04-24T15:04:57.035939Z","iopub.execute_input":"2025-04-24T15:04:57.036188Z","iopub.status.idle":"2025-04-24T15:04:57.990013Z","shell.execute_reply.started":"2025-04-24T15:04:57.036164Z","shell.execute_reply":"2025-04-24T15:04:57.989280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = px.bar(filtered_df, x='Year', y='Predicted_DEI', color='University',\n             barmode='group',\n             labels={'DEI': 'Count of DEI Tweets'},\n             title='Predicted Top 5 Universities DEI Tweet Counts by Year')\n\n# Show the plot\nfig.show()","metadata":{"trusted":true,"id":"rjX5P7rXogSD","execution":{"iopub.status.busy":"2025-04-24T15:04:57.990957Z","iopub.execute_input":"2025-04-24T15:04:57.991188Z","iopub.status.idle":"2025-04-24T15:04:59.105904Z","shell.execute_reply.started":"2025-04-24T15:04:57.991166Z","shell.execute_reply":"2025-04-24T15:04:59.104944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Percentage of DEI tweets in labeled dataset","metadata":{"id":"_vwjO8niogSD"}},{"cell_type":"code","source":"df['Year'] = df['Date'].dt.year\n\n# Step 2: Group by year and count total tweets and DEI-related tweets\nyearly_counts = df.groupby('Year').agg(\n    Total_Tweets=('DEI', 'count'),\n    DEI_Tweets=('DEI', 'sum')\n).reset_index()\n\n# Step 3: Calculate percentage of DEI-related tweets\nyearly_counts['DEI_Percentage'] = (yearly_counts['DEI_Tweets'] / yearly_counts['Total_Tweets']) * 100\n\n# Step 4: Plot the results\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Year', y='DEI_Percentage', data=yearly_counts, palette='viridis')\n\nplt.title('Percentage of DEI-Related Tweets by Year', fontsize=16)\nplt.xlabel('Year', fontsize=14)\nplt.ylabel('Percentage of DEI Tweets (%)', fontsize=14)\nplt.xticks(rotation=45)  # Rotate x-ticks for better visibility\nplt.tight_layout()\n\n# Save the figure if needed\nplt.savefig('/kaggle/working/DEI_Percentage_by_Year.png', dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"id":"Tbg1954sogSE","execution":{"iopub.status.busy":"2025-04-24T15:04:59.106976Z","iopub.execute_input":"2025-04-24T15:04:59.107241Z","iopub.status.idle":"2025-04-24T15:05:00.670700Z","shell.execute_reply.started":"2025-04-24T15:04:59.107215Z","shell.execute_reply":"2025-04-24T15:05:00.669416Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Percentage of Predicted DEI Tweets over the Year","metadata":{"id":"msXYPQEdogSF"}},{"cell_type":"code","source":"predicted_df['Year'] = predicted_df['Date'].dt.year\n\n# Step 2: Group by year and count total tweets and DEI-related tweets\nyearly_counts = predicted_df.groupby('Year').agg(\n    Total_Tweets=('Predicted_DEI', 'count'),\n    DEI_Tweets=('Predicted_DEI', 'sum')\n).reset_index()\n\n# Step 3: Calculate percentage of DEI-related tweets\nyearly_counts['DEI_Percentage'] = (yearly_counts['DEI_Tweets'] / yearly_counts['Total_Tweets']) * 100\n\n# Step 4: Plot the results\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Year', y='DEI_Percentage', data=yearly_counts, palette='viridis')\n\nplt.title('Percentage of Predicted DEI-Related Tweets by Year', fontsize=16)\nplt.xlabel('Year', fontsize=14)\nplt.ylabel('Percentage of DEI Tweets (%)', fontsize=14)\nplt.xticks(rotation=45)  # Rotate x-ticks for better visibility\nplt.tight_layout()\n\n# Save the figure if needed\nplt.savefig('/kaggle/working/DEI_Percentage_by_Year.png', dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"id":"dXuz5O_gogSF","execution":{"iopub.status.busy":"2025-04-24T15:05:00.672063Z","iopub.status.idle":"2025-04-24T15:05:00.672550Z","shell.execute_reply.started":"2025-04-24T15:05:00.672286Z","shell.execute_reply":"2025-04-24T15:05:00.672309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\n# Create a line chart using Plotly\nfig = px.line(yearly_counts,\n              x='Year',\n              y='DEI_Percentage',\n              markers=True,  # Show markers at data points\n              title='Percentage of Predicted DEI-Related Tweets by Year')\n\n# Customize the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Percentage of DEI Tweets (%)',\n    title_x=0.5,  # Center the title\n    width=900,  # Set figure size\n    height=600\n)\n\n# Rotate x-ticks for better visibility\nfig.update_xaxes(tickangle=45)\n\n# Show the figure\nfig.show()\n\n# Optional: Save the figure (using plotly's write_image function if needed)\n# fig.write_image('/kaggle/working/DEI_Percentage_by_Year_LineChart.png')","metadata":{"trusted":true,"id":"v2ygjfN1ogSG","execution":{"iopub.status.busy":"2025-04-24T15:05:00.673747Z","iopub.status.idle":"2025-04-24T15:05:00.674050Z","shell.execute_reply.started":"2025-04-24T15:05:00.673904Z","shell.execute_reply":"2025-04-24T15:05:00.673919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.graph_objects as go\n\n# Create traces for DEI Tweet Count and DEI Percentage\ntrace1 = go.Scatter(\n    x=predicted_dei_tweets_by_year['Year'],\n    y=predicted_dei_tweets_by_year['DEI_Tweet_Count'],\n    mode='lines+markers',\n    name='DEI Tweet Count',\n    line=dict(color='blue', width=2),\n    marker=dict(color='blue')\n)\n\ntrace2 = go.Scatter(\n    x=yearly_counts['Year'],\n    y=yearly_counts['DEI_Percentage'],\n    mode='lines+markers',\n    name='DEI Percentage (%)',\n    line=dict(color='green', width=2, dash='dash'),\n    marker=dict(color='green'),\n    yaxis='y2'  # Specify secondary y-axis\n)\n\n# Create the layout with dual y-axes\nlayout = go.Layout(\n    title='Predicted DEI-Related Tweet Counts and Percentage Over Time',\n    xaxis=dict(title='Year', title_font=dict(size=14)),\n    yaxis=dict(\n        title='DEI Tweet Count',\n        titlefont=dict(color='blue', size=14),\n        tickfont=dict(color='blue')\n    ),\n    yaxis2=dict(\n        title='DEI Percentage (%)',\n        titlefont=dict(color='green', size=14),\n        tickfont=dict(color='green'),\n        overlaying='y',\n        side='right'\n    ),\n    width=800,\n    height=500,\n    legend=dict(\n        orientation=\"h\",  # Horizontal orientation\n        yanchor=\"bottom\",\n        y=1.03,  # Position above plot\n        xanchor=\"center\",\n        x=0.5\n    ),\n\n)\n\n# Create the figure\nfig = go.Figure(data=[trace1, trace2], layout=layout)\n\n# Show the plot\nfig.show()","metadata":{"trusted":true,"id":"jNLPLLViogSG","execution":{"iopub.status.busy":"2025-04-24T15:05:00.675057Z","iopub.status.idle":"2025-04-24T15:05:00.675512Z","shell.execute_reply.started":"2025-04-24T15:05:00.675263Z","shell.execute_reply":"2025-04-24T15:05:00.675285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming your DataFrame is already created and named df\n\n# Step 1: Extract the year from the Date column\ndf['Year'] = df['Date'].dt.year\n\n# Step 2: Group by year and count total tweets and DEI-related tweets\nyearly_counts = df.groupby('Year').agg(\n    Total_Tweets=('DEI', 'count'),\n    DEI_Tweets=('DEI', 'sum')\n).reset_index()\n\n# Step 3: Melt the DataFrame to get it in the long format for plotting\nyearly_counts_melted = yearly_counts.melt(id_vars='Year',\n                                           value_vars=['Total_Tweets', 'DEI_Tweets'],\n                                           var_name='Tweet_Type',\n                                           value_name='Count')\n\n# Step 4: Plot the results\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Year', y='Count', hue='Tweet_Type', data=yearly_counts_melted, palette='viridis')\n\nplt.title('Total Tweets and DEI-Related Tweets by Year', fontsize=16)\nplt.xlabel('Year', fontsize=14)\nplt.ylabel('Number of Tweets', fontsize=14)\nplt.xticks(rotation=45)  # Rotate x-ticks for better visibility\nplt.legend(title='Tweet Type')\nplt.tight_layout()\n\n# Save the figure if needed\nplt.savefig('/kaggle/working/Total_and_DEI_Tweets_by_Year.png', dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"id":"ZSe1TIz5ogSH","execution":{"iopub.status.busy":"2025-04-24T15:05:00.677039Z","iopub.status.idle":"2025-04-24T15:05:00.677486Z","shell.execute_reply.started":"2025-04-24T15:05:00.677246Z","shell.execute_reply":"2025-04-24T15:05:00.677269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming your DataFrame is already created and named df\n\n# Step 1: Extract the year from the Date column\npredicted_df['Year'] = predicted_df['Date'].dt.year\n\n# Step 2: Group by year and count total tweets and DEI-related tweets\nyearly_counts = predicted_df.groupby('Year').agg(\n    Total_Tweets=('Predicted_DEI', 'count'),\n    DEI_Tweets=('Predicted_DEI', 'sum')\n).reset_index()\n\n# Step 3: Melt the DataFrame to get it in the long format for plotting\nyearly_counts_melted = yearly_counts.melt(id_vars='Year',\n                                           value_vars=['Total_Tweets', 'DEI_Tweets'],\n                                           var_name='Tweet_Type',\n                                           value_name='Count')\n\n# Step 4: Plot the results\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Year', y='Count', hue='Tweet_Type', data=yearly_counts_melted, palette='viridis')\n\nplt.title('Total Unseen Tweets and Predicted DEI-Related Tweets by Year', fontsize=16)\nplt.xlabel('Year', fontsize=14)\nplt.ylabel('Number of Tweets', fontsize=14)\nplt.xticks(rotation=45)  # Rotate x-ticks for better visibility\nplt.legend(title='Tweet Type')\nplt.tight_layout()\n\n# Save the figure if needed\nplt.savefig('/kaggle/working/Total_and_DEI_Tweets_by_Year.png', dpi=300)\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"id":"v_NfL1ZOogSJ","execution":{"iopub.status.busy":"2025-04-24T15:05:00.678844Z","iopub.status.idle":"2025-04-24T15:05:00.679273Z","shell.execute_reply.started":"2025-04-24T15:05:00.679047Z","shell.execute_reply":"2025-04-24T15:05:00.679069Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TF-IDF Analysis","metadata":{"id":"XB5vYXDPogSL"}},{"cell_type":"code","source":"predicted_df.head()","metadata":{"trusted":true,"id":"GZMt7pEDogSL","execution":{"iopub.status.busy":"2025-04-24T15:05:00.680633Z","iopub.status.idle":"2025-04-24T15:05:00.681054Z","shell.execute_reply.started":"2025-04-24T15:05:00.680832Z","shell.execute_reply":"2025-04-24T15:05:00.680855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hbcu_list = ['Florida A&M University',\n'North Carolina Agricultural & Technical State University'\n'Howard University',\n'Spelman College',\n'Morgan State University']","metadata":{"trusted":true,"id":"I_GkCX3bogSM","execution":{"iopub.status.busy":"2025-04-24T15:05:00.681992Z","iopub.status.idle":"2025-04-24T15:05:00.682426Z","shell.execute_reply.started":"2025-04-24T15:05:00.682188Z","shell.execute_reply":"2025-04-24T15:05:00.682209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predicted_dei_tweets = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['University'].isin(hbcu_list))]\npredicted_dei_tweets = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2019)]\n\npredicted_dei_tweets.head()","metadata":{"_kg_hide-input":false,"trusted":true,"id":"wUBuivM7ogSM","execution":{"iopub.status.busy":"2025-04-24T15:05:00.683954Z","iopub.status.idle":"2025-04-24T15:05:00.684398Z","shell.execute_reply.started":"2025-04-24T15:05:00.684157Z","shell.execute_reply":"2025-04-24T15:05:00.684180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Preprocess Tweets","metadata":{"id":"yX3hg2-NogSN"}},{"cell_type":"code","source":"# Download stopwords and wordnet once if not already downloaded\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"trusted":true,"id":"zkI5WmubogSO","execution":{"iopub.status.busy":"2025-04-24T15:05:00.686029Z","iopub.status.idle":"2025-04-24T15:05:00.686306Z","shell.execute_reply.started":"2025-04-24T15:05:00.686172Z","shell.execute_reply":"2025-04-24T15:05:00.686186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"xVfsJsjNogSO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"trusted":true,"id":"maGJ3DVpogSO","execution":{"iopub.status.busy":"2025-04-24T15:05:00.687492Z","iopub.status.idle":"2025-04-24T15:05:00.687796Z","shell.execute_reply.started":"2025-04-24T15:05:00.687651Z","shell.execute_reply":"2025-04-24T15:05:00.687667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize stopwords and lemmatizer\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()","metadata":{"trusted":true,"id":"dIb7-hA-ogSP","execution":{"iopub.status.busy":"2025-04-24T15:05:00.689269Z","iopub.status.idle":"2025-04-24T15:05:00.689592Z","shell.execute_reply.started":"2025-04-24T15:05:00.689444Z","shell.execute_reply":"2025-04-24T15:05:00.689459Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the preprocessing function\ndef preprocess_text(text):\n    # Lowercase the text\n    text = text.lower()\n\n    # Remove URLs\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n\n    # Remove punctuation and numbers\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n\n    # Tokenize, remove stopwords, and lemmatize\n    tokens = text.split()\n    tokens = [word for word in tokens if word not in stop_words]\n    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n\n    # Join tokens back into a single string\n    return ' '.join(tokens)","metadata":{"trusted":true,"id":"1mdtiAEOogSP","execution":{"iopub.status.busy":"2025-04-24T15:05:00.690997Z","iopub.status.idle":"2025-04-24T15:05:00.691267Z","shell.execute_reply.started":"2025-04-24T15:05:00.691136Z","shell.execute_reply":"2025-04-24T15:05:00.691150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess each DEI tweet in the 'Tweet' column\npredicted_dei_tweets['Processed_Tweet'] = predicted_dei_tweets['Tweet'].apply(preprocess_text)","metadata":{"trusted":true,"id":"tVTKEe6yogSQ","execution":{"iopub.status.busy":"2025-04-24T15:05:00.692191Z","iopub.status.idle":"2025-04-24T15:05:00.692497Z","shell.execute_reply.started":"2025-04-24T15:05:00.692325Z","shell.execute_reply":"2025-04-24T15:05:00.692357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dei_keywords = [\n    \"Diversity\", \"Equity\", \"Equality\", \"Inclusion\", \"Inclusive\", \"Fairness\", \"Justice\",\n    \"Representation\", \"Bias\", \"Privilege\", \"Discrimination\", \"Intersectionality\",\n    \"Accessibility\", \"Allyship\", \"Belonging\", \"Cultural competence\", \"Social justice\",\n    \"Equal pay\", \"Anti-racism\", \"Marginalization\", \"Oppression\", \"Civil rights\",\n    \"Gender equality\", \"Racial equality\", \"LGBTQ+\", \"LGBTQ+\", \"LGBTQ\",\n    \"Disability rights\", \"Neurodiversity\", \"Multiculturalism\", \"Safe space\",\n    \"Inclusive language\", \"Unconscious bias\", \"Microaggressions\", \"Cultural sensitivity\",\n    \"Advocacy\", \"Veteran\", \"Women\", \"Men\", \"Girl\", \"Boy\", \"Gender\",\n    \"Female\", \"Male\", \"Non-binary\", \"Transgender\", \"Queer\", \"Black\",\n    \"African American\", \"Asian\", \"Latino\", \"Hispanic\", \"Indigenous\",\n    \"Native American\", \"Pacific Islander\", \"White\", \"Person of Color\", \"BIPOC\",\n    \"Disabled\", \"Neurodiverse\", \"Immigrant\", \"Refugee\", \"Minority\",\n    \"Underrepresented\", \"Migrant\", \"Ethnicity\", \"Race\", \"Sexual orientation\",\n    \"Sexual\", \"Religion\", \"Christian\", \"Muslim\", \"Jewish\", \"Buddhist\",\n    \"Hindu\", \"Interfaith\", \"Faith-based\", \"Cultural background\",\n    \"Ethnic diversity\", \"Ethnic\", \"Ageism\", \"Sexism\", \"Racism\",\n    \"Homophobia\", \"Transphobia\", \"Xenophobia\", \"Islamophobia\", \"Ableism\",\n    \"Sexual harassment\", \"Workplace diversity\", \"Gender identity\", \"Poverty\",\n    \"Atheism\", \"Mental health\", \"Mental\", \"Multicultural\", \"Diverse\",\n    \"Interracial\", \"Equal\", \"Equalizing\", \"Equalized\", \"Justifying\",\n    \"Justified\", \"Nationality\", \"National\", \"Nationalized\", \"Nationalizing\",\n    \"Heritage\", \"Ancestry\", \"LGBTQ+\", \"Heterosexual\", \"Heterosexuality\",\n    \"Homosexual\", \"Homosexuality\", \"Bisexual\", \"Bisexuality\", \"Pansexual\",\n    \"Pansexuality\", \"Asexual\", \"Asexuality\", \"Cisgender\", \"Genderqueer\",\n    \"Genderfluid\", \"Agender\", \"Faith\", \"Belief\", \"Beliefs\",\n    \"Spirituality\", \"Spiritual\", \"Spiritualizing\", \"Spiritualized\",\n    \"Bilingual\", \"Bilingualism\", \"Multilingual\", \"Multilingualism\",\n    \"Age\", \"Aging\", \"Aged\", \"Generational\", \"Elderly\",\n    \"Partnership\", \"Partnering\", \"Partnered\", \"Military\", \"Veteran\",\n    \"Veteranized\", \"Cognitive\", \"Cognition\", \"Neurodiversity\", \"Neurodiverse\",\n    \"Disability\", \"Disabled\", \"Disabling\", \"Mobility\", \"Mobile\",\n    \"Mobilizing\", \"Mobilized\", \"Accessibility\", \"Accessible\", \"Inclusive\",\n    \"Tolerance\", \"Tolerating\", \"Tolerant\", \"Worldview\", \"Identity\",\n    \"Identified\", \"Identify\", \"Awareness\", \"Aware\", \"Representation\",\n    \"Representing\", \"Represented\", \"Representative\", \"Fairness\",\n    \"Fair\", \"Fairing\", \"Equity\", \"Equitable\", \"Equitably\",\n    \"Impartiality\", \"Impartial\", \"Disparity\", \"Disparate\",\n    \"Disparaging\", \"Disparaged\", \"Barrier\", \"Barring\", \"Access\",\n    \"Accessing\", \"Biasing\", \"Biased\", \"Biasness\", \"Socializing\",\n    \"Socialized\", \"Empowerment\", \"Empowering\", \"Empowered\",\n    \"Belonging\", \"Belong\", \"Belonged\", \"Inclusion\", \"Included\",\n    \"Including\", \"Christianity\", \"Christian\", \"Christianized\",\n    \"Christianizing\", \"Islam\", \"Islamic\", \"Islamized\",\n    \"Islamizing\", \"Judaism\", \"Jewish\", \"Buddhism\", \"Buddhist\",\n    \"Hinduism\", \"Hindu\", \"Atheism\", \"Atheist\", \"Agnosticism\",\n    \"Agnostic\", \"Global\", \"Minor\", \"Emotion\", \"Emotional\",\n    \"Cross-culture\", \"Cross culture\", \"Cross-cultural\", \"Anti-bias\",\n    \"#Melanin\", \"Black Futures Month\", \"Black Men\", \"Black Panther Movement\",\n    \"Racism\", \"Antiracism\", \"racial profiling\", \"community freedom\",\n    \"people of color\", \"racial justice\", \"race relations\",\n    \"White Supremacy\", \"Anti Black\", \"BLM\", \"Black Lives Matter\", \"Black Kids Matter\", \"George Floyd\",\"black lives matter\", \"#blm\", \"no justice no peace\", \"say their names\",\n    \"i can't breathe\", \"hands up don't shoot\", \"#blackhistorymonth\",\n    \"#nomorenames\", \"#endpolicebrutality\", \"#defundthepolice\", \"acab\",\n    \"#wewillbreathe\", \"#theshowmustbepaused\", \"#blackouttuesday\",\n    \"power to the people\", \"rest in power\", \"#racismisavirus\",\n    \"#blackexcellence\", \"#blackjoy\", \"#supportblackbusiness\",\n    \"#buyblack\", \"#blackownedbusiness\", \"#communityfirst\",\n    \"#powertothepeople\", \"#buildingcommunity\", \"#strongertogether\",\n    \"#blackexcellence\", \"#blacksuccess\", \"say their name\",\n    \"never forget\", \"#justiceforbreonnataylor\", \"#remembertheirnames\",\n    \"#sayhername\", \"#takeaknee\", \"#abolishthepolice\",\n    \"#wewillnotforget\", \"#foreverinourhearts\", \"#amplifyblackvoices\",\n    \"#neveragain\", \"#blmprotests\", \"legacy lives on\", \"#juneteenth\",\n    \"#blackintech\", \"#blacktwitter\", \"#blackgirlscode\",\n    \"#blackentrepreneurs\", \"#melanin\", \"black futures month\",\n    \"black men\", \"black panther movement\", \"black\", \"racial\", \"racism\", \"antiracism\",\n    \"racial profiling\", \"community freedom\", \"people of color\",\n    \"racial justice\", \"race relations\", \"#shareblackstories\",\n    \"#amplifymelanatedvoices\", \"#passthemic\", \"#raiseyourvoice\",\n    \"#speakup\", \"#useyourplatform\", \"#aminext\", \"#sharethemic\",\n    \"#dosomething\", \"#takeaction\", \"#makenoise\", \"#disruptthenarrative\",\n    \"#wecannotbesilent\", \"#thisstopstoday\", \"#notonemore\",\n    \"freedom now\", \"white silence is violence\", \"black power\",\n    \"anti black racism\", \"black scientists\", \"black owned\",\n    \"black kids matter\", \"now we transform\", \"white supremacy\",\n    \"#blackqueerlives\",\"blackhistorymonth\", \"george floyd\", \"systemic racism\", \"hbcu\", \"police brutality\"\n]","metadata":{"trusted":true,"id":"fh__xgrDogSR","execution":{"iopub.status.busy":"2025-04-24T15:05:00.694026Z","iopub.status.idle":"2025-04-24T15:05:00.694325Z","shell.execute_reply.started":"2025-04-24T15:05:00.694182Z","shell.execute_reply":"2025-04-24T15:05:00.694197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hbcu_list = ['Florida A&M University',\n'North Carolina Agricultural & Technical State University'\n'Howard University',\n'Spelman University',\n'Morgan State University']","metadata":{"trusted":true,"id":"8B0Wr1EMogSW","execution":{"iopub.status.busy":"2025-04-24T15:05:00.695371Z","iopub.status.idle":"2025-04-24T15:05:00.695660Z","shell.execute_reply.started":"2025-04-24T15:05:00.695517Z","shell.execute_reply":"2025-04-24T15:05:00.695531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert DEI keywords to lowercase\ndei_keywords_lower = [kw.lower() for kw in dei_keywords]","metadata":{"trusted":true,"id":"ItLoSz9HogSX","execution":{"iopub.status.busy":"2025-04-24T15:05:00.697016Z","iopub.status.idle":"2025-04-24T15:05:00.697304Z","shell.execute_reply.started":"2025-04-24T15:05:00.697164Z","shell.execute_reply":"2025-04-24T15:05:00.697179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_top_dei_keywords(df, keywords, top_n):\n\n    df['Processed_Tweet'] = df['Tweet'].apply(preprocess_text)\n\n    # Initialize the TF-IDF vectorizer\n    vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n\n    # Fit and transform the preprocessed tweets\n    tfidf_matrix = vectorizer.fit_transform(df['Processed_Tweet'])\n\n    # Get feature names (terms) and their corresponding scores\n    feature_names = vectorizer.get_feature_names_out()\n    tfidf_scores = tfidf_matrix.sum(axis=0).A1  # Sum scores across all tweets for each term\n\n    # Create a DataFrame for TF-IDF scores\n    tfidf_df = pd.DataFrame({\n        'Keyword': feature_names,\n        'TF-IDF Score': tfidf_scores\n    })\n\n    # Filter for keywords related to DEI\n    dei_tfidf_df = tfidf_df[tfidf_df['Keyword'].isin(keywords)]\n\n    # Sort by TF-IDF score in descending order\n    dei_tfidf_df = dei_tfidf_df.sort_values(by='TF-IDF Score', ascending=False)\n\n    # Return the top N keywords\n    return dei_tfidf_df.head(top_n)\n\n","metadata":{"trusted":true,"id":"oOcYvNzMogSY","execution":{"iopub.status.busy":"2025-04-24T15:05:00.698653Z","iopub.status.idle":"2025-04-24T15:05:00.698942Z","shell.execute_reply.started":"2025-04-24T15:05:00.698799Z","shell.execute_reply":"2025-04-24T15:05:00.698814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_dei = predicted_df[predicted_df['Predicted_DEI'] == 1]\npredicted_hbcu = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['University'].isin(hbcu_list))]\npredicted_non_hbcu = predicted_df[(predicted_df['Predicted_DEI']==1) & (~predicted_df['University'].isin(hbcu_list))]\npredicted_2015 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2015)]\npredicted_2016 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2016)]\npredicted_2017 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2017)]\npredicted_2018 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2018)]\npredicted_2019 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2019)]\npredicted_2020 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2020)]\npredicted_2021 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2021)]\npredicted_2022 = predicted_df[(predicted_df['Predicted_DEI']==1) & (predicted_df['Year']==2022)]\n","metadata":{"trusted":true,"id":"jsDUsOSMogSa","execution":{"iopub.status.busy":"2025-04-24T15:05:00.699839Z","iopub.status.idle":"2025-04-24T15:05:00.700135Z","shell.execute_reply.started":"2025-04-24T15:05:00.699995Z","shell.execute_reply":"2025-04-24T15:05:00.700010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top_n = 20","metadata":{"trusted":true,"id":"YnaajVMZogSb","execution":{"iopub.status.busy":"2025-04-24T15:05:00.701100Z","iopub.status.idle":"2025-04-24T15:05:00.701426Z","shell.execute_reply.started":"2025-04-24T15:05:00.701253Z","shell.execute_reply":"2025-04-24T15:05:00.701268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"top_dei_keywords = get_top_dei_keywords(predicted_dei,  dei_keywords_lower, top_n)\ntop_keywords_2019 = get_top_dei_keywords(predicted_2019, dei_keywords_lower, top_n)\ntop_keywords_2020 = get_top_dei_keywords(predicted_2020, dei_keywords_lower, top_n)\ntop_keywords_2021 = get_top_dei_keywords(predicted_2021, dei_keywords_lower, top_n)\ntop_keywords_2022 = get_top_dei_keywords(predicted_2022, dei_keywords_lower, top_n)\ntop_keywords_hbcu = get_top_dei_keywords(predicted_hbcu, dei_keywords_lower, top_n)\ntop_keywords_non_hbcu = get_top_dei_keywords(predicted_non_hbcu, dei_keywords_lower, top_n)","metadata":{"trusted":true,"id":"gj6kuoxcogSc","execution":{"iopub.status.busy":"2025-04-24T15:05:00.702992Z","iopub.status.idle":"2025-04-24T15:05:00.703440Z","shell.execute_reply.started":"2025-04-24T15:05:00.703197Z","shell.execute_reply":"2025-04-24T15:05:00.703219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hbcu_list = ['Florida A&M University',\n'North Carolina Agricultural & Technical State University'\n'Howard University',\n'Spelman University',\n'Morgan State University']","metadata":{"trusted":true,"id":"Gfj7-VhRogSd","execution":{"iopub.status.busy":"2025-04-24T15:05:00.704590Z","iopub.status.idle":"2025-04-24T15:05:00.705038Z","shell.execute_reply.started":"2025-04-24T15:05:00.704813Z","shell.execute_reply":"2025-04-24T15:05:00.704836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up the subplots\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\naxes = axes.flatten()  # Flatten the 2D array of axes to easily iterate over\n\n# List of years and their corresponding data\nyears = [2015, 2016, 2017, 2018]\ntop_keywords_list = [top_keywords_2019, top_keywords_2020, top_keywords_2021, top_keywords_2022]\n\n# Create a horizontal bar chart for each year\nfor ax, year, top_keywords in zip(axes, years, top_keywords_list):\n    # Ensure only the top 10 keywords are plotted\n    top_keywords = top_keywords.head(10)\n\n    ax.barh(top_keywords['Keyword'], top_keywords['TF-IDF Score'], color='skyblue')\n    ax.set_title(f\"Top 10 DEI Keywords - {year}\")\n    ax.set_xlabel(\"TF-IDF Score\")\n    ax.set_ylabel(\"Keywords\")\n    ax.invert_yaxis()  # Invert y-axis to show the highest score on top\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"id":"KbP_doeRogSe","execution":{"iopub.status.busy":"2025-04-24T15:05:00.706232Z","iopub.status.idle":"2025-04-24T15:05:00.706693Z","shell.execute_reply.started":"2025-04-24T15:05:00.706461Z","shell.execute_reply":"2025-04-24T15:05:00.706484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up the subplots\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\naxes = axes.flatten()  # Flatten the 2D array of axes to easily iterate over\n\n# List of years and their corresponding data\nyears = [2019, 2020, 2021, 2022]\ntop_keywords_list = [top_keywords_2019, top_keywords_2020, top_keywords_2021, top_keywords_2022]\n\n# Create a horizontal bar chart for each year\nfor ax, year, top_keywords in zip(axes, years, top_keywords_list):\n    # Ensure only the top 10 keywords are plotted\n    top_keywords = top_keywords.head(10)\n\n    ax.barh(top_keywords['Keyword'], top_keywords['TF-IDF Score'], color='skyblue')\n    ax.set_title(f\"Top 10 DEI Keywords - {year}\")\n    ax.set_xlabel(\"TF-IDF Score\")\n    ax.set_ylabel(\"Keywords\")\n    ax.invert_yaxis()  # Invert y-axis to show the highest score on top\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"id":"7Saud5aLogSf","execution":{"iopub.status.busy":"2025-04-24T15:05:00.707993Z","iopub.status.idle":"2025-04-24T15:05:00.708288Z","shell.execute_reply.started":"2025-04-24T15:05:00.708145Z","shell.execute_reply":"2025-04-24T15:05:00.708160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Create a figure with two subplots\nfig, axs = plt.subplots(1, 2, figsize=(14, 6))\n\n# Bar chart for HBCUs\naxs[0].barh(top_keywords_hbcu['Keyword'], top_keywords_hbcu['TF-IDF Score'], color='skyblue')\naxs[0].set_xlabel('TF-IDF Score')\naxs[0].set_title('Top DEI Keywords from HBCU Tweets')\naxs[0].invert_yaxis()  # Invert y-axis\n\n# Bar chart for Non-HBCUs\naxs[1].barh(top_keywords_non_hbcu['Keyword'], top_keywords_non_hbcu['TF-IDF Score'], color='lightcoral')\naxs[1].set_xlabel('TF-IDF Score')\naxs[1].set_title('Top DEI Keywords from Non-HBCU Tweets')\naxs[1].invert_yaxis()  # Invert y-axis\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"id":"WCAbGHBHogSh","execution":{"iopub.status.busy":"2025-04-24T15:05:00.709186Z","iopub.status.idle":"2025-04-24T15:05:00.709508Z","shell.execute_reply.started":"2025-04-24T15:05:00.709333Z","shell.execute_reply":"2025-04-24T15:05:00.709373Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Contribution of Universities in DEI Conversation","metadata":{"id":"TGr34jJ2ogSi"}},{"cell_type":"code","source":"top_and_hbcu = [\n    \"New York University\",\n    \"University of California, Davis\",\n    \"University of Michigan--Ann Arbor\",\n    \"American University\",\n    \"Johns Hopkins University\",\n    \"The Pennsylvania State University\",\n    \"Stanford University\",\n    \"Florida A&M University\",\n    \"North Carolina Agricultural & Technical State University\",\n    \"Howard University\",\n    \"Spelman College\",\n    \"Morgan State University\",\n    \"Georgetown University\",\n    \"Simmons University\",\n    \"Georgia State University\"\n]","metadata":{"trusted":true,"id":"AytQ2TuKogSj","execution":{"iopub.status.busy":"2025-04-24T15:05:00.710898Z","iopub.status.idle":"2025-04-24T15:05:00.711177Z","shell.execute_reply.started":"2025-04-24T15:05:00.711037Z","shell.execute_reply":"2025-04-24T15:05:00.711050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter the DataFrame for the selected universities\nfiltered_df = predicted_df[predicted_df['University'].isin(top_and_hbcu)]","metadata":{"trusted":true,"id":"2GlLt2osogSj","execution":{"iopub.status.busy":"2025-04-24T15:05:00.712205Z","iopub.status.idle":"2025-04-24T15:05:00.712510Z","shell.execute_reply.started":"2025-04-24T15:05:00.712354Z","shell.execute_reply":"2025-04-24T15:05:00.712378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the total DEI tweets for each university\ndei_counts = filtered_df.groupby('University')['Predicted_DEI'].sum().reset_index()\ndei_counts.columns = ['University', 'DEI_Tweet_Count']","metadata":{"trusted":true,"id":"Il2tEVESogSl","execution":{"iopub.status.busy":"2025-04-24T15:05:00.714283Z","iopub.status.idle":"2025-04-24T15:05:00.714616Z","shell.execute_reply.started":"2025-04-24T15:05:00.714467Z","shell.execute_reply":"2025-04-24T15:05:00.714483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_dei_tweets = predicted_df['Predicted_DEI'].sum()\ndei_counts['Contribution (%)'] = (dei_counts['DEI_Tweet_Count'] / total_dei_tweets) * 100","metadata":{"trusted":true,"id":"na9DpkYuogSm","execution":{"iopub.status.busy":"2025-04-24T15:05:00.715533Z","iopub.status.idle":"2025-04-24T15:05:00.715840Z","shell.execute_reply.started":"2025-04-24T15:05:00.715690Z","shell.execute_reply":"2025-04-24T15:05:00.715706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming predicted_df is your DataFrame\ntop_dei_unis = [\n    \"New York University\",\n    \"University of California, Davis\",\n    \"University of Michigan--Ann Arbor\",\n    \"American University\",\n    \"Johns Hopkins University\",\n    \"The Pennsylvania State University\",\n    \"Stanford University\",\n    \"Georgetown University\",\n    \"Simmons University\",\n    \"Georgia State University\"\n]\n\nhbcu_list = [\n    \"Florida A&M University\",\n    \"North Carolina Agricultural & Technical State University\",\n    \"Howard University\",\n    \"Spelman College\",\n    \"Morgan State University\"\n]\n\n# Calculate DEI contributions for top DEI universities\nfiltered_dei = predicted_df[predicted_df['University'].isin(top_dei_unis)]\ndei_counts_dei_unis = filtered_dei.groupby('University')['Predicted_DEI'].sum().reset_index()\ntotal_dei_tweets = predicted_df['Predicted_DEI'].sum()\ndei_counts_dei_unis['Contribution (%)'] = (dei_counts_dei_unis['Predicted_DEI'] / total_dei_tweets) * 100\n\n# Sort the contributions in descending order\ndei_counts_dei_unis = dei_counts_dei_unis.sort_values(by='Contribution (%)', ascending=False)\n\n# Calculate DEI contributions for HBCUs\nfiltered_hbcus = predicted_df[predicted_df['University'].isin(hbcu_list)]\ndei_counts_hbcus = filtered_hbcus.groupby('University')['Predicted_DEI'].sum().reset_index()\ndei_counts_hbcus['Contribution (%)'] = (dei_counts_hbcus['Predicted_DEI'] / total_dei_tweets) * 100\n\n# Sort the contributions in descending order\ndei_counts_hbcus = dei_counts_hbcus.sort_values(by='Contribution (%)', ascending=False)\n\n# Set up the matplotlib figure with subplots\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n\n# Bar plot for top DEI universities\nsns.barplot(data=dei_counts_dei_unis, x='Contribution (%)', y='University', ax=axes[0], palette='viridis')\naxes[0].set_title('Contribution of Top DEI Universities to the Overall DEI Conversation')\naxes[0].set_xlabel('Contribution (%)')\naxes[0].set_ylabel('University')\n\n# Bar plot for HBCUs\nsns.barplot(data=dei_counts_hbcus, x='Contribution (%)', y='University', ax=axes[1], palette='viridis')\naxes[1].set_title('Contribution of HBCUs to the Overall DEI Conversation')\naxes[1].set_xlabel('Contribution (%)')\naxes[1].set_ylabel('University')\n\n# Adjust layout\nplt.tight_layout()\n\n# Display the plot\nplt.show()","metadata":{"trusted":true,"id":"WLW4CBJCogSm","execution":{"iopub.status.busy":"2025-04-24T15:05:00.717201Z","iopub.status.idle":"2025-04-24T15:05:00.717671Z","shell.execute_reply.started":"2025-04-24T15:05:00.717429Z","shell.execute_reply":"2025-04-24T15:05:00.717451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport plotly.express as px\n\n# Assuming predicted_df is your DataFrame and it has a 'Year' column\npredicted_df['Year'] = predicted_df['Year'].astype(str)  # Ensure Year is a string for plotting\n\n# Top 5 DEI universities\ntop_dei_unis = [\n    \"New York University\",\n    \"University of California, Davis\",\n    \"University of Michigan--Ann Arbor\",\n    \"American University\",\n    \"Johns Hopkins University\"\n]\n\n# HBCU list\nhbcu_list = [\n    \"Florida A&M University\",\n    \"North Carolina Agricultural & Technical State University\",\n    \"Howard University\",\n    \"Spelman College\",\n    \"Morgan State University\"\n]\n\n# Calculate DEI contributions for top DEI universities by year\nfiltered_dei = predicted_df[predicted_df['University'].isin(top_dei_unis)]\ndei_counts_dei_unis_yearly = filtered_dei.groupby(['Year', 'University'])['Predicted_DEI'].sum().reset_index()\ntotal_dei_tweets = predicted_df['Predicted_DEI'].sum()\ndei_counts_dei_unis_yearly['Contribution (%)'] = (dei_counts_dei_unis_yearly['Predicted_DEI'] / total_dei_tweets) * 100\n\n# Calculate DEI contributions for HBCUs by year\nfiltered_hbcus = predicted_df[predicted_df['University'].isin(hbcu_list)]\ndei_counts_hbcus_yearly = filtered_hbcus.groupby(['Year', 'University'])['Predicted_DEI'].sum().reset_index()\ndei_counts_hbcus_yearly['Contribution (%)'] = (dei_counts_hbcus_yearly['Predicted_DEI'] / total_dei_tweets) * 100\n\n# Create a line chart for top DEI universities with markers\nfig_dei_unis = px.line(dei_counts_dei_unis_yearly,\n                        x='Year',\n                        y='Contribution (%)',\n                        color='University',\n                        markers=True,  # Add markers to the line chart\n                        title='Contribution of Top 5 DEI Universities to the Overall DEI Conversation by Year',\n                        labels={'Contribution (%)': 'Contribution (%)', 'Year': 'Year'})\n\n# Create a line chart for HBCUs with markers\nfig_hbcu = px.line(dei_counts_hbcus_yearly,\n                    x='Year',\n                    y='Contribution (%)',\n                    color='University',\n                    markers=True,  # Add markers to the line chart\n                    title='Contribution of HBCUs to the Overall DEI Conversation by Year',\n                    labels={'Contribution (%)': 'Contribution (%)', 'Year': 'Year'})\n\n# Show both figures\nfig_dei_unis.show()\nfig_hbcu.show()\n","metadata":{"trusted":true,"id":"n7kVlYPlogSn","execution":{"iopub.status.busy":"2025-04-24T15:05:00.719526Z","iopub.status.idle":"2025-04-24T15:05:00.719985Z","shell.execute_reply.started":"2025-04-24T15:05:00.719746Z","shell.execute_reply":"2025-04-24T15:05:00.719770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"WyqwT6gzogSo","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"R37WZKGSogSo","trusted":true},"outputs":[],"execution_count":null}]}